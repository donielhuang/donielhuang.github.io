<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Daniel's Blog</title>
    <description>Daniel's Blogs</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 10 Sep 2019 15:31:10 +0800</pubDate>
    <lastBuildDate>Tue, 10 Sep 2019 15:31:10 +0800</lastBuildDate>
    <generator>Jekyll v3.6.2</generator>
    
      <item>
        <title>Spark Cassandra Spanbykey</title>
        <description>&lt;h3 id=&quot;spark-cassandra-spanbykey&quot;&gt;spark cassandra spanByKey&lt;/h3&gt;

&lt;p&gt;原本有一段程式是從 cassandra 把資料查出來，轉成 person 物件後，再根據 person id 當作 key，然後 reduceByKey 後做 Person merge．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val persons = {
  sc.cassandraTable[PersonByTime](cassandraKeyspace, cassandraTableName).keyBy[(String, String, Long)](&quot;groupid&quot;,&quot;id&quot;,&quot;inserttime&quot;).map(p =&amp;gt; {
    (p._1._2 , PersonParser.modelString(p._2.personString))
  }).reduceByKey {
    Person.merge
  }.filter(p =&amp;gt; !&quot;&quot;.equals(p._1)).coalesce(500)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;執行的結果 shuffle write 數量非常高，有可能是因為 reduceByKey 的關係．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/spark/sparkCassandraSpanbykey/sparkCassandraSpanbykey_1.jpg&quot; alt=&quot;sparkCassandraSpanbykey_1.jpg&quot; height=&quot;400px&quot; width=&quot;800px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;於是使用 spark cassandra connector 提供的 spanByKey 根據 groupid 以及 id 來轉換成 spark rdd，等於說根據這樣的 partition 該 partition 的資料已經都是要 merge 的資料了．
所以不需要再 reduceByKey 只要把 partition 的 person 全部都 merge 起來．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val persons = {
  sc.cassandraTable[PersonByTime](cassandraKeyspace, cassandraTableName).keyBy[(String, String)](&quot;groupid&quot;,&quot;id&quot;).spanByKey.coalesce(500).mapPartitions(
   iter =&amp;gt; {
      for(p &amp;lt;- iter) yield {
        val groupKey = p._1._1
        val personKey = p._1._2
        val person = p._2.foldLeft(new Person(groupid = groupKey,id = personKey)) {
          case (p , ps) =&amp;gt; {
            Person.merge(p , PersonParser.modelString(ps.personString))
          }
        }
        (personKey , person)
      }
    }
  )
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;這樣修改後 shuffle write 從 84.4 G 變成 3.1 M．&lt;/p&gt;

&lt;p&gt;官網解釋 &lt;a href=&quot;https://github.com/datastax/spark-cassandra-connector/blob/master/doc/3_selection.md&quot;&gt;spanByKey&lt;/a&gt; :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;The methods spanBy and spanByKey iterate every Spark partition locally and put every RDD item into the same group as long as the key doesn't change.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Tue, 10 Sep 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/spark/2019/09/10/spark-cassandra-spanByKey.html</link>
        <guid isPermaLink="true">http://localhost:4000/spark/2019/09/10/spark-cassandra-spanByKey.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Grafana Helloword</title>
        <description>&lt;h3 id=&quot;grafana&quot;&gt;grafana&lt;/h3&gt;

&lt;p&gt;使用 grafana 來監控一些數據．&lt;/p&gt;

&lt;p&gt;先下載 grafana-6.2.0-beta1、prometheus-2.9.2.darwin-amd64、pushgateway-0.8.0.darwin-amd64&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; mygrafana &amp;gt; ll
total 202904
drwxr-xr-x  12 daniel  staff   384B May  9 10:49 grafana-6.2.0-beta1
drwxr-xr-x@ 10 daniel  staff   320B May  9 18:46 prometheus-2.9.2.darwin-amd64
drwxr-xr-x@  7 daniel  staff   224B May  9 18:03 pushgateway-0.8.0.darwin-amd64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;啟動-grafana&quot;&gt;啟動 grafana&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./grafana-server web
INFO[05-15|10:28:13] Starting Grafana                         logger=server version=6.2.0-beta1 commit=9d877d6 branch=HEAD compiled=2019-05-07T22:08:46+0800
INFO[05-15|10:28:13] Config loaded from                       logger=settings file=/Users/daniel/1-project/2-ght/mygrafana/grafana-6.2.0-beta1/conf/defaults.ini
INFO[05-15|10:28:13] Config loaded from                       logger=settings file=/Users/daniel/1-project/2-ght/mygrafana/grafana-6.2.0-beta1/conf/custom.ini
INFO[05-15|10:28:13] Path Home                                logger=settings path=/Users/daniel/1-project/2-ght/mygrafana/grafana-6.2.0-beta1
INFO[05-15|10:28:13] Path Data                                logger=settings path=/Users/daniel/1-project/2-ght/mygrafana/grafana-6.2.0-beta1/data
INFO[05-15|10:28:13] Path Logs                                logger=settings path=/Users/daniel/1-project/2-ght/mygrafana/grafana-6.2.0-beta1/data/log
INFO[05-15|10:28:13] Path Plugins                             logger=settings path=/Users/daniel/1-project/2-ght/mygrafana/grafana-6.2.0-beta1/data/plugins
INFO[05-15|10:28:13] Path Provisioning                        logger=settings path=/Users/daniel/1-project/2-ght/mygrafana/grafana-6.2.0-beta1/conf/provisioning
INFO[05-15|10:28:13] App mode production                      logger=settings
INFO[05-15|10:28:13] Initializing SqlStore                    logger=server
INFO[05-15|10:28:13] Connecting to DB                         logger=sqlstore dbtype=sqlite3
INFO[05-15|10:28:13] Starting DB migration                    logger=migrator
INFO[05-15|10:28:13] Initializing HTTPServer                  logger=server
INFO[05-15|10:28:13] Initializing InternalMetricsService      logger=server
INFO[05-15|10:28:13] Initializing RemoteCache                 logger=server
INFO[05-15|10:28:13] Initializing QuotaService                logger=server
INFO[05-15|10:28:13] Initializing LoginService                logger=server
INFO[05-15|10:28:13] Initializing PluginManager               logger=server
INFO[05-15|10:28:13] Starting plugin search                   logger=plugins
INFO[05-15|10:28:13] Initializing RenderingService            logger=server
INFO[05-15|10:28:13] Initializing AlertingService             logger=server
INFO[05-15|10:28:13] Initializing DatasourceCacheService      logger=server
INFO[05-15|10:28:13] Initializing HooksService                logger=server
INFO[05-15|10:28:13] Initializing SearchService               logger=server
INFO[05-15|10:28:13] Initializing ServerLockService           logger=server
INFO[05-15|10:28:13] Initializing TracingService              logger=server
INFO[05-15|10:28:13] Initializing UsageStatsService           logger=server
INFO[05-15|10:28:13] Initializing UserAuthTokenService        logger=server
INFO[05-15|10:28:13] Initializing CleanUpService              logger=server
INFO[05-15|10:28:13] Initializing NotificationService         logger=server
INFO[05-15|10:28:13] Initializing provisioningServiceImpl     logger=server
INFO[05-15|10:28:13] Initializing Stream Manager
INFO[05-15|10:28:13] HTTP Server Listen                       logger=http.server address=0.0.0.0:3000 protocol=http subUrl= socket=

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/grafana/grafana-day1_1.jpg&quot; alt=&quot;grafana-day1_1.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一開始會有預設一組帳密 : admin / admin&lt;/p&gt;

&lt;h4 id=&quot;啟動-prometheus-&quot;&gt;啟動 prometheus :&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;prometheus-2.9.2.darwin-amd64 &amp;gt; ./prometheus --config.file=prometheus.yml
level=info ts=2019-05-15T02:37:38.200Z caller=main.go:285 msg=&quot;no time or size retention was set so using the default time retention&quot; duration=15d
level=info ts=2019-05-15T02:37:38.200Z caller=main.go:321 msg=&quot;Starting Prometheus&quot; version=&quot;(version=2.9.2, branch=HEAD, revision=d3245f15022551c6fc8281766ea62db4d71e2747)&quot;
level=info ts=2019-05-15T02:37:38.200Z caller=main.go:322 build_context=&quot;(go=go1.12.4, user=root@1d43b6951e8f, date=20190424-15:38:47)&quot;
level=info ts=2019-05-15T02:37:38.200Z caller=main.go:323 host_details=(darwin)
level=info ts=2019-05-15T02:37:38.200Z caller=main.go:324 fd_limits=&quot;(soft=4864, hard=unlimited)&quot;
level=info ts=2019-05-15T02:37:38.200Z caller=main.go:325 vm_limits=&quot;(soft=unlimited, hard=unlimited)&quot;
level=info ts=2019-05-15T02:37:38.202Z caller=main.go:640 msg=&quot;Starting TSDB ...&quot;
level=info ts=2019-05-15T02:37:38.202Z caller=web.go:416 component=web msg=&quot;Start listening for connections&quot; address=0.0.0.0:9090
level=info ts=2019-05-15T02:37:38.204Z caller=repair.go:47 component=tsdb msg=&quot;found healthy block&quot; mint=1557371288998 maxt=1557374400000 ulid=01DADKA0ME61GBCXZZ0YVWQKMG
level=info ts=2019-05-15T02:37:38.205Z caller=repair.go:47 component=tsdb msg=&quot;found healthy block&quot; mint=1557374400000 maxt=1557381600000 ulid=01DADP8RS3Z27R79HFDRWZX31Y
level=info ts=2019-05-15T02:37:38.205Z caller=repair.go:47 component=tsdb msg=&quot;found healthy block&quot; mint=1557381600000 maxt=1557388800000 ulid=01DADX48WVR4ZAX2N09TQ634V9
level=info ts=2019-05-15T02:37:38.362Z caller=main.go:655 msg=&quot;TSDB started&quot;
level=info ts=2019-05-15T02:37:38.362Z caller=main.go:724 msg=&quot;Loading configuration file&quot; filename=prometheus.yml
level=info ts=2019-05-15T02:37:38.383Z caller=main.go:751 msg=&quot;Completed loading of configuration file&quot; filename=prometheus.yml
level=info ts=2019-05-15T02:37:38.384Z caller=main.go:609 msg=&quot;Server is ready to receive web requests.&quot;
level=info ts=2019-05-15T02:37:44.781Z caller=compact.go:499 component=tsdb msg=&quot;write block&quot; mint=1557388800000 maxt=1557396000000 ulid=01DAWNMK7NWPY77XXGBE31759Q duration=728.109783ms
level=info ts=2019-05-15T02:37:44.812Z caller=head.go:540 component=tsdb msg=&quot;head GC completed&quot; duration=2.494261ms
level=info ts=2019-05-15T02:37:45.645Z caller=compact.go:499 component=tsdb msg=&quot;write block&quot; mint=1557396000000 maxt=1557403200000 ulid=01DAWNMKZG1HEZM796YENH8N3V duration=829.050418ms
level=info ts=2019-05-15T02:37:45.674Z caller=head.go:540 component=tsdb msg=&quot;head GC completed&quot; duration=1.907243ms
level=info ts=2019-05-15T02:37:48.836Z caller=compact.go:444 component=tsdb msg=&quot;compact blocks&quot; count=2 mint=1557371288998 maxt=1557381600000 ulid=01DAWNMQ6HRM85GWCQ2KFHP58B sources=&quot;[01DADKA0ME61GBCXZZ0YVWQKMG 01DADP8RS3Z27R79HFDRWZX31Y]&quot; duration=722.930613ms

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/grafana/grafana-day1_2.jpg&quot; alt=&quot;grafana-day1_2.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;設定 grafana 的 data source :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_3.jpg&quot; alt=&quot;grafana-day1_3.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;輸入 Prometheus 的 URL :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_4.jpg&quot; alt=&quot;grafana-day1_4.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;建立新的 dashboard :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_5.jpg&quot; alt=&quot;grafana-day1_5.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;建立新的 query :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_6.jpg&quot; alt=&quot;grafana-day1_6.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接著在 query 的條件下 go_gc_duration_seconds，grafana 會定時從 prometheus 讀取數值並呈現圖表 :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_7.jpg&quot; alt=&quot;grafana-day1_7.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;也可以在 prometheus 查詢資料 :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_8.jpg&quot; alt=&quot;grafana-day1_8.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;啟動-pushgateway&quot;&gt;啟動 pushgateway&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./pushgateway  --web.listen-address &quot;:9091&quot; --persistence.file /Users/daniel/1-project/2-ght/mygrafana/pushgateway-0.8.0.darwin-amd64/data/file
INFO[0000] Starting pushgateway (version=0.8.0, branch=HEAD, revision=d90bf3239c5ca08d72ccc9e2e2ff3a62b99a122e)  source=&quot;main.go:65&quot;
INFO[0000] Build context (go=go1.11.8, user=root@00855c3ed64f, date=20190413-11:29:57)  source=&quot;main.go:66&quot;
INFO[0000] Listening on :9091.                           source=&quot;main.go:108&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/grafana/grafana-day1_9.jpg&quot; alt=&quot;grafana-day1_9.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接著修改 prometheus 的 prometheus.yml 檔案，新增來源，prometheus 就會去 pushgateway 讀取資料 :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  - job_name: pushgateway
    static_configs:
    - targets: ['localhost:9091']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;prometheus.yml :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# my global config
global:
  scrape_interval:     15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - &quot;first_rules.yml&quot;
  # - &quot;second_rules.yml&quot;

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=&amp;lt;job_name&amp;gt;` to any timeseries scraped from this config.
  - job_name: 'prometheus'

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
    - targets: ['localhost:9090']

  - job_name: pushgateway
    static_configs:
    - targets: ['localhost:9091']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以看到 target 多一個 pushgateway :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_10.jpg&quot; alt=&quot;grafana-day1_10.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;post 資料給 pushgateway :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;mappingcount 500&quot; | curl --data-binary @- http://localhost:9091/metrics/job/idmapping_report
echo &quot;personsCount 5000&quot; | curl --data-binary @- http://localhost:9091/metrics/job/idmapping_report
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;可以在 pushgateway 上看到 post 的資料 : 
&lt;img src=&quot;/static/img/grafana/grafana-day1_11.jpg&quot; alt=&quot;grafana-day1_11.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以在 prometheus 查到到 pushgateway 的資料 : 
&lt;img src=&quot;/static/img/grafana/grafana-day1_12.jpg&quot; alt=&quot;grafana-day1_12.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;接著就可以在 grafana 拉想要的圖表 :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_13.jpg&quot; alt=&quot;grafana-day1_13.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;dashboard 畫面 :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_14.jpg&quot; alt=&quot;grafana-day1_14.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;流程圖 :&lt;br /&gt;
&lt;img src=&quot;/static/img/grafana/grafana-day1_15.jpg&quot; alt=&quot;grafana-day1_15.jpg&quot; height=&quot;60%&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;使用-node_exporter&quot;&gt;使用 node_exporter&lt;/h3&gt;

&lt;p&gt;下載 node_exporter :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone https://github.com/prometheus/node_exporter.git
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;下 make 時遇到下面錯誤 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; make
xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;安裝 xcode&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;xcode-select --install
sudo xcode-select -switch /
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;安裝完 make 還是遇到很多問題，在 Mac 上 make 不成功．&lt;/p&gt;

&lt;p&gt;所以先用測試環境直接執行 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/usr/sbin/node_exporter --web.listen-address=:4100 --collector.textfile.directory /Users/daniel/1-project/2-ght/mygrafana/nodeExporter/textfile_collector
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;修改 prometheus.yml 檔案，新增來源，prometheus 就會去 node-exporter 讀取資料 :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- job_name: 'node-exporter'
    static_configs:
            - targets: ['HDFS1:4100', 'HDFS2:4100', 'HDFS3:4100', 'Rediscluster1:4100', 'Rediscluster2:4100', 'Rediscluster3:4100']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;可以在很多台機器上執行 node-exporter．&lt;/p&gt;

&lt;p&gt;只要在 /Users/daniel/1-project/2-ght/mygrafana/nodeExporter/textfile_collector 路徑產生 prom 檔案，按照格式寫入就可以讓 prometheus 抓到 node-exporter 的資料 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/Users/daniel/1-project/2-ght/mygrafana/nodeExporter/textfile_collector/chtWeeklyReport.prom
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;chtWeeklyReport.prom 檔案內容格式如下 :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;labelcount_report{content=&quot;totalLabelCount&quot;} 50000
labelcount_report{content=&quot;clientLabelCount&quot;} 1000
idmapping_report{content=&quot;mappingcount&quot;} 500
idmapping_report{content=&quot;personsCount&quot;} 5000
idmapping_report{content=&quot;mappingPercentage&quot;} 0.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Wed, 15 May 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/grafana/2019/05/15/grafana-helloword.html</link>
        <guid isPermaLink="true">http://localhost:4000/grafana/2019/05/15/grafana-helloword.html</guid>
        
        
        <category>grafana</category>
        
      </item>
    
      <item>
        <title>Zeppelin Helloword</title>
        <description>&lt;h3 id=&quot;zeppelin&quot;&gt;zeppelin&lt;/h3&gt;

&lt;p&gt;使用 zeppelin 透過 spark 對 cassandra 做查詢．&lt;/p&gt;

&lt;p&gt;先用 docker 下載後，再開 http://localhost:8080&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;docker pull apache/zeppelin:0.8.1
docker run -p 8080:8080 --rm apache/zeppelin:0.8.1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;建立 notebook&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_1.jpg&quot; alt=&quot;zeppelin_1.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;原本程式的寫法 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val spark: SparkSession = SparkSession.builder().appName(&quot;KmeansLookLikePerson&quot;)
      .config(&quot;spark.sql.warehouse.dir&quot;, &quot;/tmp&quot;)
      .config(&quot;spark.cassandra.connection.host&quot;, EnrichConfig.CASSANDRA_IPS)
      .config(&quot;spark.cassandra.auth.username&quot;, EnrichConfig.CASSANDRA_USER)
      .config(&quot;spark.cassandra.auth.password&quot;, EnrichConfig.CASSANDRA_PSWD)
      .getOrCreate()

val allPersons = spark.sparkContext.cassandraTable[(String,Seq[Double])](&quot;miks2&quot;,&quot;testpersonlabelvector&quot;)
  .select(&quot;id&quot;,&quot;labelvector&quot;).keyBy[Tuple1[String]](&quot;id&quot;)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;寫到 notebook 裡面，可參考 &lt;a href=&quot;https://zeppelin.apache.org/docs/0.7.2/interpreter/spark.html#sparkcontext-sqlcontext-sparksession-zeppelincontext&quot;&gt;spark Interpreter for zeppelin&lt;/a&gt;，
所以 zeppelin 預設就會給一個 sc 就是 sparkContext．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import com.datastax.spark.connector._

val allPersons = sc.cassandraTable[(String,Seq[Double])](&quot;miks2&quot;,&quot;testpersonlabelvector&quot;)
      .select(&quot;id&quot;,&quot;labelvector&quot;).keyBy[Tuple1[String]](&quot;id&quot;)

allPersons.take(5).foreach(p =&amp;gt; println(p._1._1))

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;那原本要設定 cassandra 的 host、username、password 要帶給 sparkContext，就要設定在 Interpreter 的 spark 設定裡．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_2.jpg&quot; alt=&quot;zeppelin_2.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;把參數設定在這裡 :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_3.jpg&quot; alt=&quot;zeppelin_3.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;那由於有使用到 spark cassandra 所以要 import library&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import com.datastax.spark.connector._
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;設定在 dependencies，加上需要的 library．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_4.jpg&quot; alt=&quot;zeppelin_4.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;zeppelin 會去 maven 或指定的 repositories 下載 library．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_5.jpg&quot; alt=&quot;zeppelin_5.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;結著只要按 run 就可以了．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_6.jpg&quot; alt=&quot;zeppelin_6.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果需要有一些視覺化的圖表，則需要先把 Dataframe 轉成 spark sql 的 table．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;looklikePersons.registerTempTable(&quot;looklikePersons&quot;)
allPersons.toDF().registerTempTable(&quot;allPersons&quot;)
seedPersons.toDF().registerTempTable(&quot;seedPersons&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;程式碼如下 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import com.datastax.spark.connector._
import org.apache.spark.ml.clustering.KMeans
import org.apache.spark.ml.linalg.Vectors

val kcluster = 2
val outputPersons = 10

val testpersonSeed = &quot;hash:9ef58b79-8aab-4e5b-bcf5-b8974991e599,hash:cd5d9c99-393b-4814-8f62-9aebcc31bd21,hash:a0c95fa1-fc44-44ff-b4ae-c407cd53f292,hash:a2ada011-53a1-4d27-9885-dbfd2b0cb969,hash:ce1283e2-a72a-4377-86f5-c03774f00641,hash:4241c150-cde7-4cb7-9306-10946cdbb639,hash:be9fcd09-a1f5-467a-9065-82a89c86af83,hash:48f3d940-f0bd-4300-9f8a-33c29c56ace6,hash:35dc9c3d-f04d-4b27-a5ce-8180ea9705ec,hash:57258600-55c5-4d94-8d15-8f754d8d14bc&quot;

val allPersons = sc.cassandraTable[(String,Seq[Double])](&quot;miks2&quot;,&quot;testpersonlabelvector&quot;)
      .select(&quot;id&quot;,&quot;labelvector&quot;).keyBy[Tuple1[String]](&quot;id&quot;)

val limitPersons = spark.sparkContext.parallelize(allPersons.take(1000))

val seedPersons = sc.cassandraTable[(String,Seq[Double])](&quot;miks2&quot;,&quot;testpersonlabelvector&quot;)
  .select(&quot;id&quot;,&quot;labelvector&quot;).where(&quot;id in ? &quot; , testpersonSeed.split(&quot;,&quot;).toSeq).keyBy[Tuple1[String]](&quot;id&quot;)

val tranDataSet = seedPersons.filter(_._2._2.size == 254).map(r =&amp;gt; ( r._2._1 ,Vectors.dense(r._2._2.toArray))).toDF(&quot;id&quot;, &quot;features&quot;)

val kmeans = new KMeans().setK(kcluster).setSeed(kcluster)
val model = kmeans.fit(tranDataSet)
val seedKmodel = sc.parallelize(model.clusterCenters)
val resultIdList = seedKmodel.cartesian(limitPersons)
  .map(ds =&amp;gt; (ds._2._1._1 , cosineSimilarity(ds._1.toArray , ds._2._2._2)))
  .sortBy(_._2 , false).take(outputPersons)

val looklikePersons = sc.parallelize(resultIdList).toDF()
looklikePersons.registerTempTable(&quot;looklikePersons&quot;)
allPersons.toDF().registerTempTable(&quot;allPersons&quot;)
seedPersons.toDF().registerTempTable(&quot;seedPersons&quot;)

def cosineSimilarity(x: Seq[Double], y: Seq[Double]): Double = {
  val v = genDot(x, y)/(magnitude(x) * magnitude(y))
  if(v.isNaN) {
    0
  } else {
    v
  }
}

def genDot(x: Seq[Double], y: Seq[Double]): Double = {
  (for((a, b) &amp;lt;- x.zip(y)) yield a * b).sum
}

def magnitude(x: Seq[Double]): Double = {
  math.sqrt(x.map(i =&amp;gt; i*i).sum)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;接著只要下 sql 按 run 就可以看到圖表&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%sql
select * from looklikePersons 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_7.jpg&quot; alt=&quot;zeppelin_7.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;使用 spark 查詢 cassandra 然後建立一個 table 建立一個 spark sql 的 table，讓 user 用 sql 下查詢並看結果．&lt;br /&gt;
先查詢要的 table 及欄位 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import com.datastax.spark.connector._

val allPersons = sc.cassandraTable(&quot;miks1&quot;,&quot;twmperson&quot;).select(&quot;id&quot;,&quot;labels&quot;).map(row =&amp;gt; (row.get[String](&quot;id&quot;) , row.get[String](&quot;labels&quot;))).toDF(&quot;id&quot;,&quot;labels&quot;)

allPersons.registerTempTable(&quot;allPersons&quot;)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 sql 查詢想要的 labels 來查看有多少人有這些 labels&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%sql
select id,labels from allPersons where labels like '%36%' or labels like '%92%'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;結果表示有 labels 36 跟 92 的人共有 241 個。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_8.jpg&quot; alt=&quot;zeppelin_8.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./bin/install-interpreter.sh --name &quot;interpreter-name&quot; --artifact org.apache.zeppelin:spark2-shims:0.8.0 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/zeppelin-0.8.1-bin-all/bin&amp;gt;./install-interpreter.sh --name &quot;interpreter-name&quot; --artifact org.apache.zeppelin:spark2-shims:0.8.0
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/miuser/enrich/zeppelin/zeppelin-0.8.1-bin-all/lib/interpreter/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/miuser/enrich/zeppelin/zeppelin-0.8.1-bin-all/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Install interpreter-name(org.apache.zeppelin:spark2-shims:0.8.0) to /home/miuser/enrich/zeppelin/zeppelin-0.8.1-bin-all/interpreter/interpreter-name ...
Interpreter interpreter-name installed under /home/miuser/enrich/zeppelin/zeppelin-0.8.1-bin-all/interpreter/interpreter-name.

1. Restart Zeppelin
2. Create interpreter setting in 'Interpreter' menu on Zeppelin GUI
3. Then you can bind the interpreter on your note
miuser@dmpn1:~/enrich/zeppelin/zeppelin-0.8.1-bin-all/bin&amp;gt;ll
total 33

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果環境是 spark 1 是使用 sc :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val allPersons = sc.cassandraTable[(String,Map[String,Double])](&quot;miks1&quot;,&quot;twmperson&quot;).select(&quot;id&quot;,&quot;labels&quot;).filter(l =&amp;gt; l._2.contains(&quot;92&quot;)).toDF(&quot;id&quot;,&quot;labels&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;如果環境是 spark 2 記得改成使用 spark(sparksession)，否則會有 dependency 的問題 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import com.datastax.spark.connector._

val allPersons = spark.sparkContext.cassandraTable[(String,Map[String,Double])](&quot;miks1&quot;,&quot;twmperson&quot;).select(&quot;id&quot;,&quot;labels&quot;).filter(l =&amp;gt; l._2.contains(&quot;92&quot;)).toDF(&quot;id&quot;,&quot;labels&quot;)

allPersons.registerTempTable(&quot;allPersons&quot;)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;這段很重要 :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SparkContext, SQLContext and ZeppelinContext are automatically created and exposed as variable names sc, sqlContext and z, respectively, in Scala, Python and R environments. Staring from 0.6.1 SparkSession is available as variable spark when you are using Spark 2.x.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;遇到下列的錯誤&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java.lang.NoSuchMethodError: io.netty.buffer.PooledByteBufAllocator.metric()Lio/netty/buffer/PooledByteBufAllocatorMetric;
  at org.apache.spark.network.util.NettyMemoryMetrics.registerMetrics(NettyMemoryMetrics.java:80)
  at org.apache.spark.network.util.NettyMemoryMetrics.&amp;lt;init&amp;gt;(NettyMemoryMetrics.java:76)
  at org.apache.spark.network.client.TransportClientFactory.&amp;lt;init&amp;gt;(TransportClientFactory.java:109)
  at org.apache.spark.network.TransportContext.createClientFactory(TransportContext.java:99)
  at org.apache.spark.rpc.netty.NettyRpcEnv.&amp;lt;init&amp;gt;(NettyRpcEnv.scala:71)
  at org.apache.spark.rpc.netty.NettyRpcEnvFactory.create(NettyRpcEnv.scala:461)
  at org.apache.spark.rpc.RpcEnv$.create(RpcEnv.scala:57)
  at org.apache.spark.SparkEnv$.create(SparkEnv.scala:249)
  at org.apache.spark.SparkEnv$.createDriverEnv(SparkEnv.scala:175)
  at org.apache.spark.SparkContext.createSparkEnv(SparkContext.scala:256)
  at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:423)
  at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
  at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:933)
  at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:924)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:924)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
  at java.lang.reflect.Method.invoke(Method.java:498)
  at org.apache.zeppelin.spark.BaseSparkScalaInterpreter.spark2CreateContext(BaseSparkScalaInterpreter.scala:259)
  at org.apache.zeppelin.spark.BaseSparkScalaInterpreter.createSparkContext(BaseSparkScalaInterpreter.scala:178)
  at org.apache.zeppelin.spark.SparkScala211Interpreter.open(SparkScala211Interpreter.scala:89)
  at org.apache.zeppelin.spark.NewSparkInterpreter.open(NewSparkInterpreter.java:102)
  at org.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:62)
  at org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:69)
  at org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:616)
  at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
  at org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)
  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
  at java.util.concurrent.FutureTask.run(FutureTask.java:266)
  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
  at java.lang.Thread.run(Thread.java:748)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;zeppelin netty jar 的版本 :&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/zeppelin/zeppelin-0.8.1-bin-all/lib&amp;gt;ll | grep netty-all
-rw-r--r--  1 miuser miuser  1779991 Oct 16 11:05 netty-all-4.0.23.Final.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;spark-2.3.1 netty jar 的版本 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/opt/spark-2.3.1-bin-hadoop2.7/jars&amp;gt;ll | grep netty-all
-rw-rw-r--  1 miuser miuser  3780056 Jun  2  2018 netty-all-4.1.17.Final.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;所以把 spark 的 netty jar copy 到 zeppelin&lt;/p&gt;

&lt;p&gt;接著遇到 Jackson 版本問題，一樣把 spark 的 jackson jar 覆蓋到 zeppelin．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;com.fasterxml.jackson.databind.JsonMappingException: Incompatible Jackson version: 2.8.11-1
  at com.fasterxml.jackson.module.scala.JacksonModule$class.setupModule(JacksonModule.scala:64)
  at com.fasterxml.jackson.module.scala.DefaultScalaModule.setupModule(DefaultScalaModule.scala:19)
  at com.fasterxml.jackson.databind.ObjectMapper.registerModule(ObjectMapper.java:747)
  at org.apache.spark.util.JsonProtocol$.&amp;lt;init&amp;gt;(JsonProtocol.scala:59)
  at org.apache.spark.util.JsonProtocol$.&amp;lt;clinit&amp;gt;(JsonProtocol.scala)
  at org.apache.spark.scheduler.EventLoggingListener$.initEventLog(EventLoggingListener.scala:303)
  at org.apache.spark.scheduler.EventLoggingListener.start(EventLoggingListener.scala:128)
  at org.apache.spark.SparkContext.&amp;lt;init&amp;gt;(SparkContext.scala:522)
  at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2493)
  at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:933)
  at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:924)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:924)
  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
  at java.lang.reflect.Method.invoke(Method.java:498)
  at org.apache.zeppelin.spark.BaseSparkScalaInterpreter.spark2CreateContext(BaseSparkScalaInterpreter.scala:259)
  at org.apache.zeppelin.spark.BaseSparkScalaInterpreter.createSparkContext(BaseSparkScalaInterpreter.scala:178)
  at org.apache.zeppelin.spark.SparkScala211Interpreter.open(SparkScala211Interpreter.scala:89)
  at org.apache.zeppelin.spark.NewSparkInterpreter.open(NewSparkInterpreter.java:102)
  at org.apache.zeppelin.spark.SparkInterpreter.open(SparkInterpreter.java:62)
  at org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:69)
  at org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:616)
  at org.apache.zeppelin.scheduler.Job.run(Job.java:188)
  at org.apache.zeppelin.scheduler.FIFOScheduler$1.run(FIFOScheduler.java:140)
  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
  at java.util.concurrent.FutureTask.run(FutureTask.java:266)
  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
  at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
  at java.lang.Thread.run(Thread.java:748)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/zeppelin/zeppelin-0.8.1-bin-all/lib&amp;gt;ll | grep jackson
-rw-r--r--  1 miuser miuser     5990 Oct 16 14:40 google-http-client-jackson-1.23.0.jar
-rw-r--r--  1 miuser miuser     6675 Oct 16 14:40 google-http-client-jackson2-1.23.0.jar
-rw-r--r--  1 miuser miuser    55784 Oct 16 11:58 jackson-annotations-2.8.0.jar
-rw-r--r--  1 miuser miuser   282634 Oct 16 14:38 jackson-core-2.8.10.jar
-rw-r--r--  1 miuser miuser   232248 Oct 16 10:56 jackson-core-asl-1.9.13.jar
-rw-r--r--  1 miuser miuser  1247444 Oct 16 14:38 jackson-databind-2.8.11.1.jar
-rw-r--r--  1 miuser miuser    18336 Oct 16 10:57 jackson-jaxrs-1.9.13.jar
-rw-r--r--  1 miuser miuser   780664 Oct 16 10:56 jackson-mapper-asl-1.9.13.jar
-rw-r--r--  1 miuser miuser    34610 Oct 16 14:38 jackson-module-jaxb-annotations-2.8.10.jar
-rw-r--r--  1 miuser miuser    27084 Oct 16 10:57 jackson-xc-1.9.13.jar
-rw-r--r--  1 miuser miuser    73055 Oct 16 14:38 jersey-media-json-jackson-2.27.jar
/zeppelin/zeppelin-0.8.1-bin-all/lib&amp;gt;rm -f jackson-*
/zeppelin/zeppelin-0.8.1-bin-all/lib&amp;gt;cp /opt/spark-2.3.1-bin-hadoop2.7/jars/jackson-* .
/zeppelin/zeppelin-0.8.1-bin-all/lib&amp;gt;ll | grep jackson
-rw-r--r--  1 miuser miuser     5990 Oct 16 14:40 google-http-client-jackson-1.23.0.jar
-rw-r--r--  1 miuser miuser     6675 Oct 16 14:40 google-http-client-jackson2-1.23.0.jar
-rw-rw-r--  1 miuser miuser    46986 Mar 12 11:35 jackson-annotations-2.6.7.jar
-rw-rw-r--  1 miuser miuser   258919 Mar 12 11:35 jackson-core-2.6.7.jar
-rw-rw-r--  1 miuser miuser   232248 Mar 12 11:35 jackson-core-asl-1.9.13.jar
-rw-rw-r--  1 miuser miuser  1165323 Mar 12 11:35 jackson-databind-2.6.7.1.jar
-rw-rw-r--  1 miuser miuser   320444 Mar 12 11:35 jackson-dataformat-yaml-2.6.7.jar
-rw-rw-r--  1 miuser miuser    18336 Mar 12 11:35 jackson-jaxrs-1.9.13.jar
-rw-rw-r--  1 miuser miuser   780664 Mar 12 11:35 jackson-mapper-asl-1.9.13.jar
-rw-rw-r--  1 miuser miuser    32612 Mar 12 11:35 jackson-module-jaxb-annotations-2.6.7.jar
-rw-rw-r--  1 miuser miuser    42858 Mar 12 11:35 jackson-module-paranamer-2.7.9.jar
-rw-rw-r--  1 miuser miuser   515645 Mar 12 11:35 jackson-module-scala_2.11-2.6.7.1.jar
-rw-rw-r--  1 miuser miuser    27084 Mar 12 11:35 jackson-xc-1.9.13.jar
-rw-r--r--  1 miuser miuser    73055 Oct 16 14:38 jersey-media-json-jackson-2.27.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.csdn.net/a376554764/article/details/84672444&quot;&gt;zeppelin 整 spark 問題&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;跑 yarn-cluster mode :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_9.jpg&quot; alt=&quot;zeppelin_9.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;p&gt;把 spark-cassandra-connector_2.11-2.3.2.jar 丟到各台的 spark lib 底下 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;/opt/spark-2.3.1-bin-hadoop2.7/jars&amp;gt;ll | grep cassandra
-rw-r--r--  1 miuser miuser  8539058 Mar 12 15:28 spark-cassandra-connector_2.11-2.3.2.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import com.datastax.spark.connector._

val findLabelIndex = &quot;3&quot;
val cassandraKeyspace = &quot;test1&quot;
val cassandraTable = &quot;test&quot;
val allPersons = spark.sparkContext.cassandraTable[(String,Map[String,Double])](cassandraKeyspace,cassandraTable).select(&quot;id&quot;,&quot;labels&quot;).filter(l =&amp;gt; l._2.contains(findLabelIndex)).toDF(&quot;id&quot;,&quot;labels&quot;)

allPersons.registerTempTable(&quot;allPersons&quot;)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;將 zeppelin 的 spark notebook 跑在 yarn 上面 :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/zeppelin/zeppelin_10.jpg&quot; alt=&quot;zeppelin_10.jpg&quot; height=&quot;80%&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Thu, 07 Mar 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/spark/2019/03/07/zeppelin-helloword.html</link>
        <guid isPermaLink="true">http://localhost:4000/spark/2019/03/07/zeppelin-helloword.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Akka_http Spark</title>
        <description>&lt;h3 id=&quot;akka-http-call-spark&quot;&gt;akka-http call spark&lt;/h3&gt;

&lt;p&gt;目的是利用 akka http 建立一個 web service 給 client 端呼叫，收到 request 後執行啟動 spark job．&lt;br /&gt;
由於 spark job 是 batch job，所以執行結果可能無法即時傳回給前端，所以可以利用一個 key 存在 cassandra，讓前端查詢該 job 執行的狀況．&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/akka/akkahttp_1.jpg&quot; alt=&quot;akkahttp_1.jpg&quot; height=&quot;400px&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;建立 cassandra table&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CREATE TABLE miks2.jobList(
jobId text,
sparkJobId text,
status text,
PRIMARY KEY(jobId)
) ;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;package&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ght&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrich&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rest&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ActorSystem&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaladsl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Http&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaladsl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marshallers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sprayjson&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SprayJsonSupport&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaladsl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaladsl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Directives&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ActorMaterializer&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;launcher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SparkLauncher&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SparkSession&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StdIn&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IdList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LooklikeInfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;likePerson&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kcluster&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;trait&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JsonSupport&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SprayJsonSupport&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DefaultJsonProtocol&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;looklikeInfoFormat&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonFormat3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LooklikeInfo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;要&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JsonSupport&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SimpleWebServer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;JsonSupport&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;system&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ActorSystem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;my-system&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;materializer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ActorMaterializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executionContext&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dispatcher&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;/*&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;://&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;192.168.6.31&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8080&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lookLikePersonWithFilePath&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;likePerson&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hdfsCsvFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrich&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;looklike&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idlist&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idlist_5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;csv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kcluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;*/&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;helloRoute&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;lookLikePersonWithFilePath&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;設定&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;接收的參數&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'likePerson.as[String],'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hdfsCsvFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'kcluster.as[String] ) {
          (likePerson , hdfsCsvFile , kcluster) =&amp;gt;
            val id = java.util.UUID.randomUUID().toString
            /*
            * spark-submit --class ght.mi.ml.KmeansLookLikePerson --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 20g --executor-cores 6 --num-executors 5 enrich-5.0.jar 1000
            * */
            val sparkLauncher = new SparkLauncher()
              .setAppResource(&quot;/home/miuser/enrich/genData/enrich-5.0.jar&quot;)
              .setMainClass(&quot;ght.mi.ml.KmeansLookLikePerson&quot;)
              .setMaster(&quot;yarn&quot;)
              .setDeployMode(&quot;cluster&quot;)
              .setConf(&quot;spark.driver.memory&quot;, &quot;4g&quot;)
              .setConf(&quot;spark.executor.memory&quot;, &quot;20g&quot;)
              .setConf(&quot;spark.executor.instances&quot;, &quot;5&quot;)
              .setConf(&quot;spark.executor.cores&quot;, &quot;6&quot;)
              .setConf(&quot;spark.driver.allowMultipleContexts&quot;, &quot;true&quot;)
              .addAppArgs(likePerson , hdfsCsvFile , kcluster , id)
              .launch()

            //會等 job 執行完才會 complete
            //sparkLauncher.waitFor()

            complete(HttpEntity(ContentTypes.`text/plain(UTF-8)`, id))
        }
      }
    }

    val jsonRoute = post {
      path(&quot;lookLikePerson&quot;) {
        // 使用 json 格式的方式接收 request，再取出 json 的值
        entity(as[LooklikeInfo]) { looklikeInfo =&amp;gt;
          val id = java.util.UUID.randomUUID().toString
          val ids = looklikeInfo.ids.mkString(&quot;,&quot;)
          val likePerson = looklikeInfo.likePerson
          val kcluster = looklikeInfo.kcluster
          /*
           * spark-submit --class ght.mi.ml.KmeansLookLikePerson --master yarn --deploy-mode cluster --driver-memory 4g --executor-memory 20g --executor-cores 6 --num-executors 5 enrich-5.0.jar 1000
           * */
          val sparkLauncher = new SparkLauncher()
            .setAppResource(&quot;/home/miuser/enrich/genData/enrich-5.0.jar&quot;)
            .setMainClass(&quot;ght.mi.ml.KmeansLookLikePersonWithJson&quot;)
            .setMaster(&quot;yarn&quot;)
            .setDeployMode(&quot;cluster&quot;)
            .setConf(&quot;spark.driver.memory&quot;, &quot;4g&quot;)
            .setConf(&quot;spark.executor.memory&quot;, &quot;20g&quot;)
            .setConf(&quot;spark.executor.instances&quot;, &quot;5&quot;)
            .setConf(&quot;spark.executor.cores&quot;, &quot;6&quot;)
            .setConf(&quot;spark.driver.allowMultipleContexts&quot;, &quot;true&quot;)
            .addAppArgs(likePerson, ids, kcluster, id)
            .launch()

          complete(HttpEntity(ContentTypes.`application/json`, &quot;{\&quot;jobid\&quot; : &quot; + id + &quot; }&quot;))
        }
      }
    }

    /*
    * http://192.168.6.31:8080/getJobStatus?jobId=42252e51-ded4-461e-8800-db3bcc04ed35
    * */
    val jobStatusRoute = path(&quot;getJobStatus&quot;) {
      get {
        parameters('&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jobId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;as&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jobId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&amp;gt;&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;LookLikePerson&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;local[*]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark.cassandra.connection.host&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;192.168.6.31,192.168.6.32,192.168.6.33&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark.cassandra.auth.username&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;miuser&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark.cassandra.auth.password&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;mimimi123&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datastax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jobStatus&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cassandraTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;miks2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;joblist&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;jobid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;sparkjobid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;jobid = ? &quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jobId&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keyBy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tuple1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;jobid&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

            &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HttpEntity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ContentTypes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UTF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)`,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jobStatus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;route&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;helloRoute&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jsonRoute&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jobStatusRoute&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bindingFuture&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bindAndHandle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;route&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;192.168.6.31&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;8080&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Server online at http://localhost:8080/&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Press RETURN to stop...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;StdIn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readLine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;until&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;presses&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bindingFuture&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trigger&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unbinding&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;onComplete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;terminate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;build.sbt :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;name := &quot;enrich-rest&quot;

version := &quot;0.1&quot;

scalaVersion := &quot;2.11.12&quot;

val akkaVersion = &quot;2.5.19&quot;
val akkaHttpVersion = &quot;10.1.7&quot;
val sparkVersion = &quot;2.3.1&quot;

libraryDependencies ++= Seq(
  &quot;org.apache.spark&quot;       %%  &quot;spark-sql&quot;                   % sparkVersion ,
  &quot;org.apache.spark&quot;       %%  &quot;spark-core&quot;                  % sparkVersion ,
  &quot;com.typesafe.akka&quot;      %%  &quot;akka-http&quot;                   % akkaHttpVersion,
  &quot;com.typesafe.akka&quot;      %%  &quot;akka-stream&quot;                 % akkaVersion,
  &quot;com.typesafe.akka&quot;      %%  &quot;akka-http-spray-json&quot;        % &quot;10.1.7&quot;,
  &quot;com.datastax.spark&quot;     %%  &quot;spark-cassandra-connector&quot;   % &quot;2.3.2&quot;,
  &quot;com.typesafe.akka&quot;      %%  &quot;akka-http-testkit&quot;           % akkaHttpVersion % Test,
  &quot;com.typesafe.akka&quot;      %%  &quot;akka-stream-testkit&quot;         % akkaVersion     % Test
)

parallelExecution in Test := false

assemblyJarName in assembly := name.value + &quot;.jar&quot;

test in assembly := {}

assemblyMergeStrategy in assembly := {
  case PathList(&quot;META-INF&quot;, xs @ _*) =&amp;gt; MergeStrategy.discard
  case PathList(&quot;reference.conf&quot;) =&amp;gt; MergeStrategy.concat
  case x =&amp;gt; MergeStrategy.first
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;直接啟動 server :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;java -cp &quot;enrich-rest.jar:netty-all-4.1.17.Final.jar&quot; ght.mi.enrich.rest.SimpleWebServer
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 curl 傳 json 資料給 lookLikePerson :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -H &quot;Content-Type: application/json&quot; -X POST -d '{&quot;likePerson&quot;:&quot;100&quot;,&quot;kcluster&quot;:&quot;5&quot;,&quot;ids&quot;:[&quot;hash:9ef58b79-8aab-4e5b-bcf5-b8974991e599&quot;,&quot;hash:87b0c3e8-7840-4d15-bb2f-9d4986e535a5&quot;]}' http://192.168.6.31:8080/lookLikePerson
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 04 Mar 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/akka/2019/03/04/akka_http-spark.html</link>
        <guid isPermaLink="true">http://localhost:4000/akka/2019/03/04/akka_http-spark.html</guid>
        
        
        <category>akka</category>
        
      </item>
    
      <item>
        <title>Akka_http Helloword</title>
        <description>&lt;h3 id=&quot;akka-http&quot;&gt;akka-http&lt;/h3&gt;

&lt;p&gt;可以參考官網的 &lt;a href=&quot;https://doc.akka.io/docs/akka-http/current/introduction.html#philosophy&quot;&gt;akka-http&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;package&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ght&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enrich&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rest&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ActorSystem&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaladsl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Http&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaladsl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scaladsl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Directives&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;akka&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ActorMaterializer&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scala&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StdIn&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SimpleWebServer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;system&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ActorSystem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;my-system&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;materializer&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ActorMaterializer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;needed&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;future&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;onComplete&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;implicit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;executionContext&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dispatcher&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;route&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hello&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;get&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;complete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HttpEntity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ContentTypes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.`&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;UTF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)`,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&amp;lt;h1&amp;gt;Say hello to akka-http&amp;lt;/h1&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bindingFuture&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Http&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bindAndHandle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;route&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;localhost&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;8080&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Server online at http://localhost:8080/&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;Press RETURN to stop...&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;StdIn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;readLine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;run&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;until&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;user&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;presses&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;bindingFuture&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;flatMap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unbind&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trigger&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unbinding&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;onComplete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;system&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;terminate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shutdown&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;when&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;接著只要發一個 http request 就可以收到 response 的內容．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;gt; curl http://localhost:8080/hello
&amp;lt;h1&amp;gt;Say hello to akka-http&amp;lt;/h1&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;但由於上面的程式只有實作 get 方法．所以使用 post 方式會收到 Unsupported HTTP method．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -X post http://localhost:8080/hello
Unsupported HTTP method
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;如果 request 的 url 不存在時就會收到下列訊息．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl http://localhost:8080/
The requested resource could not be found.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Tue, 26 Feb 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/akka/2019/02/26/akka_http-helloword.html</link>
        <guid isPermaLink="true">http://localhost:4000/akka/2019/02/26/akka_http-helloword.html</guid>
        
        
        <category>akka</category>
        
      </item>
    
      <item>
        <title>Spark Kmeans</title>
        <description>&lt;h3 id=&quot;spark-k-means&quot;&gt;spark k-means&lt;/h3&gt;

&lt;p&gt;Seed 代表一開始初始化 random 的點．K 表示 cluster 的數量．setInitMode 目前支持 random 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;k-means||&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;k-means||&lt;/code&gt; 是 k-means++．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val spark = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;testtest&quot;).config(&quot;spark.cassandra.connection.host&quot;, &quot;192.168.6.31&quot;).getOrCreate()
val dataset = spark.createDataFrame(Seq(
  (0, Vectors.sparse(6, Seq((0, 1.0), (1, 1.0), (2, 1.0)))), // [1.0 , 1.0 , 1.0 , 0   , 0   , 0  ]
  (1, Vectors.sparse(6, Seq((2, 1.0), (3, 1.0), (4, 1.0)))), // [0   , 0   , 1.0 , 1.0 , 1.0 , 0  ]
  (2, Vectors.sparse(6, Seq((0, 1.0), (2, 1.0), (4, 1.0)))), // [1.0 , 0   , 1.0 , 0   , 1.0 , 0  ]
  (3, Vectors.sparse(6, Seq((1, 1.0), (3, 1.0), (4, 1.0)))), // [0   , 1.0 , 0   , 1.0 , 1.0 , 0  ]
  (4, Vectors.sparse(6, Seq((1, 1.0), (3, 1.0), (5, 1.0)))), // [0   , 1.0 , 0   , 1.0 , 0   , 1.0]
  (5, Vectors.sparse(6, Seq((2, 1.0), (3, 1.0), (5, 1.0)))), // [0   , 0   , 1.0 , 1.0 , 0   , 1.0]
  (6, Vectors.sparse(6, Seq((1, 1.0), (2, 1.0), (4, 1.0)))), // [0   , 1.0 , 1.0 , 0   , 1.0 , 0  ]
  (7, Vectors.sparse(6, Seq((0, 1.0), (1, 1.0), (3, 1.0))))  // [1.0 , 1.0 , 0   , 1.0 , 0   , 0  ]
)).toDF(&quot;id&quot;, &quot;features&quot;)

// Trains a k-means model.
val kmeans = new KMeans().setK(3).setSeed(1L)

val model = kmeans.fit(dataset)

// Make predictions
val predictions = model.transform(dataset)

// Evaluate clustering by computing Silhouette score
val evaluator = new ClusteringEvaluator()

val silhouette = evaluator.evaluate(predictions)
println(s&quot;Silhouette with squared euclidean distance = $silhouette&quot;)

// Shows the result.
println(&quot;Cluster Centers: &quot;)
model.clusterCenters.foreach(println)

predictions.show()
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;印出結果 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Silhouette with squared euclidean distance = 0.11111111111111134
Cluster Centers: 
[0.3333333333333333,0.6666666666666666,0.3333333333333333,1.0,0.0,0.6666666666666666]
[0.3333333333333333,0.3333333333333333,0.6666666666666666,0.6666666666666666,1.0,0.0]
[0.5,1.0,1.0,0.0,0.5,0.0]
+---+--------------------+----------+
| id|            features|prediction|
+---+--------------------+----------+
|  0|(6,[0,1,2],[1.0,1...|         2|
|  1|(6,[2,3,4],[1.0,1...|         1|
|  2|(6,[0,2,4],[1.0,1...|         1|
|  3|(6,[1,3,4],[1.0,1...|         1|
|  4|(6,[1,3,5],[1.0,1...|         0|
|  5|(6,[2,3,5],[1.0,1...|         0|
|  6|(6,[1,2,4],[1.0,1...|         2|
|  7|(6,[0,1,3],[1.0,1...|         0|
+---+--------------------+----------+

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;實際在餵給 KMeans 的資料集時，會需要一個 features 的欄位，可透過 Vectors.dense 來將 Array[Double] 轉成 Vector．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;seedPersons.map(r =&amp;gt; ( r._2._1 ,Vectors.dense(r._2._2.toArray))).toDF(&quot;id&quot;, &quot;features&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val outputPersons = 100
//10 count
val testpersonSeed = &quot;hash:9ef58b79-8aab-4e5b-bcf5-b8974991e599,hash:cd5d9c99-393b-4814-8f62-9aebcc31bd21,hash:a0c95fa1-fc44-44ff-b4ae-c407cd53f292,hash:a2ada011-53a1-4d27-9885-dbfd2b0cb969,hash:ce1283e2-a72a-4377-86f5-c03774f00641,hash:4241c150-cde7-4cb7-9306-10946cdbb639,hash:be9fcd09-a1f5-467a-9065-82a89c86af83,hash:48f3d940-f0bd-4300-9f8a-33c29c56ace6,hash:35dc9c3d-f04d-4b27-a5ce-8180ea9705ec,hash:57258600-55c5-4d94-8d15-8f754d8d14bc&quot;

val inputIdList = testpersonSeed
val spark = SparkSession.builder()
      .appName(&quot;LookLikePersonLSH&quot;)
      .master(&quot;local[*]&quot;)
      .config(&quot;spark.cassandra.connection.host&quot;, &quot;192.168.6.31,192.168.6.32,192.168.6.33&quot;)
      .config(&quot;spark.cassandra.auth.username&quot;, &quot;miuser&quot;)
      .config(&quot;spark.cassandra.auth.password&quot;, &quot;mimimi123&quot;)
      .getOrCreate()

import spark.implicits._

val allPersons = spark.sparkContext.cassandraTable[(String,Seq[Double])](&quot;miks2&quot;,&quot;testpersonlabelvector&quot;)
  .select(&quot;id&quot;,&quot;labelvector&quot;).keyBy[Tuple1[String]](&quot;id&quot;)

val seedPersons = spark.sparkContext.cassandraTable[(String,Seq[Double])](&quot;miks2&quot;,&quot;testpersonlabelvector&quot;)
  .select(&quot;id&quot;,&quot;labelvector&quot;).where(&quot;id in ? &quot; , testpersonSeed.split(&quot;,&quot;).toSeq).keyBy[Tuple1[String]](&quot;id&quot;)

val tranDataSet = seedPersons.map(r =&amp;gt; ( r._2._1 ,Vectors.dense(r._2._2.toArray))).toDF(&quot;id&quot;, &quot;features&quot;)

val kmeans = new KMeans().setK(5).setSeed(5L)
val model = kmeans.fit(tranDataSet)

val seedKmodel = spark.sparkContext.parallelize(model.clusterCenters)
val resultIdList = seedKmodel.cartesian(allPersons)
  .map(ds =&amp;gt; (ds._2._1._1 , LabelVectorUtil().cosineSimilarity(ds._1.toArray , ds._2._2._2)))
  .sortBy(_._2 , false).take(outputPersons)

spark.sparkContext.parallelize(resultIdList).saveAsTextFile(&quot;/enrich/tempResult/KmeansLookLikePerson&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;跑 Kmeans 如果遇到下列錯誤時，可能因為丟給 KMeans 裡的向量的維度有的有不一樣，可以先檢查 data 的部分．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;User class threw exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 4 times, most recent failure: Lost task 0.3 in stage 3.0 (TID 7, dmpn1, executor 5): java.lang.IllegalArgumentException: requirement failed
at scala.Predef$.require(Predef.scala:212)
at org.apache.spark.mllib.util.MLUtils$.fastSquaredDistance(MLUtils.scala:507)
at org.apache.spark.mllib.clustering.KMeans$.fastSquaredDistance(KMeans.scala:590)
at org.apache.spark.mllib.clustering.KMeans$$anonfun$findClosest$1.apply(KMeans.scala:564)
at org.apache.spark.mllib.clustering.KMeans$$anonfun$findClosest$1.apply(KMeans.scala:558)
at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
at org.apache.spark.mllib.clustering.KMeans$.findClosest(KMeans.scala:558)
at org.apache.spark.mllib.clustering.KMeans$$anonfun$6$$anonfun$apply$2.apply(KMeans.scala:284)
at org.apache.spark.mllib.clustering.KMeans$$anonfun$6$$anonfun$apply$2.apply(KMeans.scala:283)
at scala.collection.Iterator$class.foreach(Iterator.scala:893)
...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;package&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ght&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ml&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SparkSession&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;datastax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;connector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clustering&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;KMeans&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DenseVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sql&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;types&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StringType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StructField&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StructType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KmeansLookLikePerson&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Unit&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputPersons&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hdfsCsvFile&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kcluster&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toInt&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jobkey&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testpersonSeed&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;hash:9ef58b79-8aab-4e5b-bcf5-b8974991e599,hash:cd5d9c99-393b-4814-8f62-9aebcc31bd21,hash:a0c95fa1-fc44-44ff-b4ae-c407cd53f292,hash:a2ada011-53a1-4d27-9885-dbfd2b0cb969,hash:ce1283e2-a72a-4377-86f5-c03774f00641,hash:4241c150-cde7-4cb7-9306-10946cdbb639,hash:be9fcd09-a1f5-467a-9065-82a89c86af83,hash:48f3d940-f0bd-4300-9f8a-33c29c56ace6,hash:35dc9c3d-f04d-4b27-a5ce-8180ea9705ec,hash:57258600-55c5-4d94-8d15-8f754d8d14bc&quot;&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SparkSession&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;builder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;appName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;KmeansLookLikePerson&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark.cassandra.connection.host&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;192.168.6.31,192.168.6.32,192.168.6.33&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark.cassandra.auth.username&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;miuser&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark.cassandra.auth.password&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;mimimi123&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getOrCreate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkId&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;applicationId&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jobkey&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkId&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveToCassandra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;miks2&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;joblist&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;implicits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;customSchema&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StructType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;Array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;StructField&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;StringType&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;com.databricks.spark.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;customSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/enrich/looklike/idlist/idlist.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqlContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;com.databricks.spark.csv&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;schema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;customSchema&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hdfsCsvFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testpersonSeed&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getAs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;collect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mkString&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allPersons&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cassandraTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;miks2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;testpersonlabelvector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;labelvector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keyBy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tuple1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seedPersons&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cassandraTable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Double&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;miks2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;testpersonlabelvector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;select&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;labelvector&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id in ? &quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;testpersonSeed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;,&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toSeq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keyBy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tuple1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tranDataSet&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seedPersons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;254&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dense&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toArray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toDF&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;features&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;p&quot;&gt;/*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;count&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d426a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ad9b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4e76&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b1ef&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3e37&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c963f14e&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1524&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;23&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c7bc27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b22&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;43f&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;be40&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ec8ac94aaca&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1524&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bc7399b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d36f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4269&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;be4d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e37e2ad4c5ff&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2032&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c39e4f3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cf27&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eb3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;8f&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e82a61cde043&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2032&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hash&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;6319&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b6cb&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e3fa&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;40&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bd24&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e1dc3ac9450a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2032&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tranDataSet&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seedPersons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;!= 254).map(r =&amp;gt; ( r._2._1 ,Vectors.dense(r._2._2.toArray))).toDF(&quot;id&quot;, &quot;features&quot;)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;tranDataSet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foreach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;println&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getAs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;String&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot; , &quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getAs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DenseVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;features&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;*/&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KMeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kcluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;setSeed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kcluster&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kmeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tranDataSet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seedKmodel&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clusterCenters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;resultIdList&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seedKmodel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cartesian&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;allPersons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LabelVectorUtil&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cosineSimilarity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toArray&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sortBy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;take&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputPersons&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;resultIdList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveAsTextFile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/enrich/tempResult/KmeansLookLikePerson&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;spark&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparkContext&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parallelize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;jobkey&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparkId&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;saveToCassandra&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;miks2&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;joblist&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;build.sbt&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import scalapb.compiler.Version.scalapbVersion

name := &quot;enrich-5.0&quot;

scalaVersion := &quot;2.11.12&quot; // spark only support scala 2.11

PB.targets in Compile := Seq(
    scalapb.gen() -&amp;gt; (sourceManaged in Compile).value
)

//val sparkVersion = &quot;2.4.0&quot;
val sparkVersion = &quot;2.3.1&quot;

libraryDependencies ++= Seq(
    &quot;org.apache.spark&quot;       %%  &quot;spark-sql&quot;                   % sparkVersion      % &quot;provided&quot;,
    &quot;org.apache.spark&quot;       %%  &quot;spark-core&quot;                  % sparkVersion      % &quot;provided&quot;,
    &quot;org.apache.spark&quot;       %%  &quot;spark-streaming&quot;             % sparkVersion      % &quot;provided&quot;,
    &quot;org.apache.spark&quot;       %%  &quot;spark-streaming-kafka-0-10&quot;  % sparkVersion      % &quot;provided&quot; exclude(&quot;net.jpountz.lz4&quot;, &quot;lz4&quot;),
    &quot;org.apache.spark&quot;       %%  &quot;spark-mllib&quot;                 % sparkVersion,
    &quot;org.mongodb.scala&quot;      %%  &quot;mongo-scala-driver&quot;          % &quot;2.3.0&quot;,
    &quot;com.datastax.spark&quot;     %%  &quot;spark-cassandra-connector&quot;   % &quot;2.3.2&quot;,
    &quot;org.scalatest&quot;          %%  &quot;scalatest&quot;                   % &quot;3.0.5&quot;           % &quot;test&quot;,
    &quot;com.thesamet.scalapb&quot;   %%  &quot;scalapb-runtime-grpc&quot;        % scalapbVersion,
    &quot;com.thesamet.scalapb&quot;   %%  &quot;scalapb-runtime&quot;             % scalapbVersion    % &quot;protobuf&quot;,
    &quot;io.grpc&quot;                %   &quot;grpc-okhttp&quot;                 % &quot;1.14.0&quot;,
    &quot;redis.clients&quot;          %   &quot;jedis&quot;                       % &quot;2.9.0&quot;,
    &quot;com.redislabs&quot;          %   &quot;spark-redis&quot;                 % &quot;2.3.1-M2&quot;,
    &quot;commons-codec&quot;          %   &quot;commons-codec&quot;               % &quot;1.11&quot;,
    &quot;com.jcraft&quot;             %   &quot;jsch&quot;                        % &quot;0.1.53&quot;,
    &quot;com.databricks&quot;         %%  &quot;spark-csv&quot;                   % &quot;1.5.0&quot;
)

parallelExecution in Test := false

assemblyJarName in assembly := name.value + &quot;.jar&quot;

test in assembly := {}

assemblyMergeStrategy in assembly := {
    case PathList(&quot;ght&quot;,&quot;mi&quot;,&quot;cht&quot; , xs @ _*) =&amp;gt; MergeStrategy.discard
    //    case PathList(&quot;ght&quot;,&quot;mi&quot;,&quot;imx&quot; , xs @ _*) =&amp;gt; MergeStrategy.discard
    case PathList(&quot;ght&quot;,&quot;mi&quot;,&quot;twm&quot; , xs @ _*) =&amp;gt; MergeStrategy.discard
    case PathList(&quot;ght&quot;,&quot;mi&quot;,&quot;grpc&quot; , xs @ _*) =&amp;gt; MergeStrategy.discard
    case PathList(&quot;ght&quot;,&quot;mi&quot;,&quot;model&quot;,&quot;proto&quot; , xs @ _*) =&amp;gt; MergeStrategy.discard
    case PathList(&quot;META-INF&quot;, xs @ _*) =&amp;gt; MergeStrategy.discard
    case x =&amp;gt; MergeStrategy.first
}

scalacOptions in ThisBuild ++= Seq(&quot;-unchecked&quot;, &quot;-deprecation&quot;)

enablePlugins(SbtProguard)
proguardOptions in Proguard += &quot;-dontoptimize&quot;
proguardOptions in Proguard ++= Seq(&quot;-dontnote&quot;, &quot;-dontwarn&quot;, &quot;-ignorewarnings&quot;,&quot;-keepattributes Signature,*Annotation*&quot;,&quot;-keep class io.** { *; }&quot;,&quot;-keep class scala.** { *; }&quot;,&quot;-keep class com.** { *; }&quot;,&quot;-keep class org.** { *; }&quot;,&quot;-keep class scalapb.** { *; }&quot;)
proguardInputs in Proguard := (dependencyClasspath in Compile).value.files
proguardFilteredInputs in Proguard ++= ProguardOptions.noFilter((packageBin in Compile).value)
proguardOptions in Proguard += ProguardOptions.keepMain(&quot;ght.**&quot;)

javaOptions in (Proguard, proguard) := Seq(&quot;-Xmx4G&quot;)

proguardMerge in Proguard := true
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;javax.inject-2.4.0-b34.jar&quot;)
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;io/netty/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;org/apache/commons/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;org/apache/hadoop/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;org/apache/spark/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;org/aopalliance/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;javax/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;java/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.last(&quot;net/jpountz/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;META-INF/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;git.properties&quot;)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;rootdoc.txt&quot;)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;ght/mi/twm/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;ght/mi/cht/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;ght/mi/imx/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;ght/mi/grpc/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;ght/mi/model/proto/.&quot;.r)
proguardMergeStrategies in Proguard += ProguardMerge.discard(&quot;NOTICE&quot;)
proguardMergeStrategies in Proguard += ProguardMerge.rename(&quot;LICENSE.*&quot;.r)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Mon, 25 Feb 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/spark/2019/02/25/spark-kmeans.html</link>
        <guid isPermaLink="true">http://localhost:4000/spark/2019/02/25/spark-kmeans.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Spark Querycassandra</title>
        <description>&lt;h3 id=&quot;spark-query-cassandra&quot;&gt;spark query Cassandra&lt;/h3&gt;

&lt;p&gt;建立 Cassandra KEYSPACE 以及 TABLE&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CREATE KEYSPACE miks2 WITH replication = {'class': 'SimpleStrategy', 'replication_factor': '1' }  AND durable_writes = true;

CREATE TABLE miks2.testpersonlabelvector(
id text,
labelvector list&amp;lt;double&amp;gt;,
PRIMARY KEY(id)
) ;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看 KEYSPACE 狀態&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nodetool status miks2 ;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用 spark Cassandra connector 對 cassandra 做查詢，詳細資料可以參考&lt;a href=&quot;https://github.com/datastax/spark-cassandra-connector&quot;&gt;spark-cassandra-connector&lt;/a&gt;．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import com.datastax.spark.connector._

val spark = SparkSession.builder()
  .appName(&quot;LookLikePersonLSH&quot;)
  .master(&quot;local[*]&quot;)
  .config(&quot;spark.cassandra.connection.host&quot;, &quot;192.168.6.31,192.168.6.32,192.168.6.33&quot;)
  .config(&quot;spark.cassandra.auth.username&quot;, &quot;miuser&quot;)
  .config(&quot;spark.cassandra.auth.password&quot;, &quot;mimimi123&quot;)
  .getOrCreate()

val allPersons = spark.sparkContext.cassandraTable[(String,Seq[Double])](&quot;miks2&quot;,&quot;testpersonlabelvector&quot;)
      .select(&quot;id&quot;,&quot;labelvector&quot;).keyBy[Tuple1[String]](&quot;id&quot;)

val testpersonSeed = &quot;hash:52f479d0-126c-4ccd-bf3b-3d99a6d3fec0,hash:79bdf00a-b739-42a5-bb3c-c55315011b52,hash:08565f43-5e61-4d4f-ac5c-d2fa2416e8f0&quot;
val seedPersons = spark.sparkContext.cassandraTable[(String,Seq[Double])](&quot;miks2&quot;,&quot;testpersonlabelvector&quot;)
      .select(&quot;id&quot;,&quot;labelvector&quot;).where(&quot;id in ? &quot; , testpersonSeed.split(&quot;,&quot;).toSeq).keyBy[Tuple1[String]](&quot;id&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;計算結果並存到 HDFS&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val tempList = seedPersons.cartesian(allPersons).map(ds =&amp;gt; (ds._1._1._1 , (ds._2._1._1 , LabelVectorUtil().cosineSimilarity(ds._1._2._2 , ds._2._2._2))))
val takeCount = (outputPersons / allPersons.getNumPartitions)
val resultIdList = tempList.mapPartitions(rowit =&amp;gt; {
    val tempDatas = rowit.toSeq.groupBy(_._1)
    val takeCnt = (takeCount / tempDatas.size) + 1
    tempDatas.map(personInfos =&amp;gt; {
      personInfos._2.sortWith(_._2._2 &amp;gt; _._2._2).take(takeCnt)
    }).flatten.toIterator
  }).cache()
resultIdList.saveAsTextFile(&quot;/enrich/tempResult/LookLikePersons&quot;)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Sat, 23 Feb 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/spark/2019/02/23/spark-queryCassandra.html</link>
        <guid isPermaLink="true">http://localhost:4000/spark/2019/02/23/spark-queryCassandra.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Spark Repartitionandsortwithinpartitions</title>
        <description>&lt;h3 id=&quot;spark-rdd-repartitionandsortwithinpartitions-測試&quot;&gt;spark RDD repartitionAndSortWithinPartitions 測試&lt;/h3&gt;

&lt;p&gt;透過 RDD 的 repartitionAndSortWithinPartitions 可以把 RDD 重新 repartition 並在新的 partition 進行排序．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val spark = SparkSession.builder().master(&quot;local[*]&quot;).appName(&quot;testtest&quot;).getOrCreate()
val data = spark.sparkContext.parallelize(Seq(5,2,1,66,3,21,52,35,10,88,7,28))
println(&quot;bdfore : &quot; + data.getNumPartitions)
val partitionData = data.zipWithIndex.repartitionAndSortWithinPartitions(new HashPartitioner(3))
println(&quot;after : &quot; + partitionData.getNumPartitions)
val accum = spark.sparkContext.longAccumulator(&quot;My Accumulator&quot;)
partitionData.mapPartitions(it =&amp;gt; {
  val topData = it.toSeq.iterator
  val dataStr = topData.mkString(&quot;;&quot;)
  dataStr.split(&quot;;&quot;).foreach(d =&amp;gt; accum.add(d.split(&quot;,&quot;)(0).replace(&quot;(&quot;,&quot;&quot;).toInt))
  println(accum.value + &quot; # &quot; + dataStr)
  topData
}).collect()
println(&quot;accum value is &quot; + accum.value)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;根據下列的結果可以看出，原來的 partition 是 8，repartition 後就變成給定的 3，partition 內容 :&lt;br /&gt;
(2,1);(5,0);(35,7) 在同一個 partition&lt;br /&gt;
(3,4);(21,5);(66,3) 在同一個 partition&lt;br /&gt;
(1,2);(7,10);(10,8);(28,11);(52,6);(88,9) 在同一個 partition&lt;br /&gt;
透過 spaark 的 Accumulator 可以看出每個 partition 的狀況，以及最後算出來的結果．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bdfore : 8
after : 3
42 # (2,1);(5,0);(35,7)
90 # (3,4);(21,5);(66,3)
186 # (1,2);(7,10);(10,8);(28,11);(52,6);(88,9)
accum value is 318
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;接著只要修改這一行，就可以達到 top N 的 效果．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val topData = it.toSeq.take(2).iterator
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;就會取各自 partition 的前 2 個 element．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;7 # (2,1);(5,0)
24 # (3,4);(21,5)
8 # (1,2);(7,10)
accum value is 39
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;如果是要針對所有的元素排序可以把 HashPartitioner 的值設 1，表示所有的元素都會在同一個 partition 裡．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val partitionData = data.zipWithIndex.repartitionAndSortWithinPartitions(new HashPartitioner(1))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;結果會是&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bdfore : 8
after : 1
3 # (1,2);(2,1)
accum value is 3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;根據-rdd-的-key-做-partition&quot;&gt;根據 RDD 的 Key 做 partition&lt;/h3&gt;

&lt;p&gt;假設有下列資料，希望根據資料的 key 來分成各自的 spark partition．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val datas = Seq(
  (1,Seq((1,2),(1,1))) ,
  (2,Seq((2,3),(2,2))) ,
  (3,Seq((4,5),(3,3))) ,
  (1,Seq((6,7),(4,4)))
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;先來看透過 spark parallelize 會怎麼分 partition．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val drdd = spark.sparkContext.parallelize(datas)
println(&quot;a-&amp;gt; &quot; + drdd.getNumPartitions)
val taccum = spark.sparkContext.longAccumulator(&quot;My Accumulator&quot;)
drdd.foreachPartition(it =&amp;gt; {
  it.foreach(t =&amp;gt; {
    taccum.add(t._1)
    println(taccum.value + &quot; ; &quot; + t._2.mkString(&quot;,&quot;))
  })
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;總共會分成 8 個 partition，但並不是我們要的．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a-&amp;gt; 8
1 ; (6,7),(4,4)
1 ; (1,2),(1,1)
2 ; (2,3),(2,2)
3 ; (4,5),(3,3)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;所以透過 groupByKey 再 partitionBy 根據 key 的人數重新 partition．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val keycount = drdd.groupByKey.count().toInt
val repartitionRdd = drdd.groupByKey.partitionBy(new HashPartitioner(keycount))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;println(&quot;keycount : &quot; + keycount)
println(&quot;b-&amp;gt; &quot; + repartitionRdd.getNumPartitions)
val accum = spark.sparkContext.longAccumulator(&quot;My Accumulator&quot;)
repartitionRdd.foreachPartition(it =&amp;gt; {
  it.foreach(t =&amp;gt; {
    accum.add(t._1)
    println(accum.value + &quot; ; &quot; + t._2.mkString(&quot;,&quot;))
  })
})
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;結果會是&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;keycount : 3
b-&amp;gt; 3
1 ; List((1,2), (1,1)),List((6,7), (4,4))
2 ; List((2,3), (2,2))
3 ; List((4,5), (3,3))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Fri, 22 Feb 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/spark/2019/02/22/spark-repartitionAndSortWithinPartitions.html</link>
        <guid isPermaLink="true">http://localhost:4000/spark/2019/02/22/spark-repartitionAndSortWithinPartitions.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Spark Lsh</title>
        <description>&lt;h3 id=&quot;spark-lsh-實作&quot;&gt;spark LSH 實作&lt;/h3&gt;

&lt;p&gt;建立一組 index 並 shuffle．透過 Stream.range 建立一組 1 到 10 的數字，並透過 random swap 的方式打亂．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val suffleIndex = shuffleIndex(Stream.range(1,10).toArray)

def shuffleIndex(arr: Array[Int]): Array[Int] = {
  val rand = new Random()
  for(i &amp;lt;- arr.size to 1 by -1) {
    swap(arr , (i-1) , rand.nextInt(i))
  }
  arr
}

def swap(arr: Array[Int], i:Int ,j:Int): Array[Int] = {
  val tmp = arr(i)
  arr(i) = arr(j)
  arr(j) = tmp
  arr
} 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;輸出結果會是&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;println(suffleIndex.mkString(&quot;,&quot;)) // 6,2,1,7,5,8,3,9,4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;建立 label 的查找順序查看該 label 是否有值，第 1 個找的是 label 8 的值，第 2 個找的是 label 2 的值，以此類推…&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val findLabelSequence = shuffleIndex(Stream.range(1,10).toArray).zipWithIndex.sortWith(_._1 &amp;lt; _._1).map(i =&amp;gt; (i._1 , (i._2 + 1)))
println(findLabelSequence.mkString(&quot;,&quot;)) // (1,8),(2,2),(3,4),(4,9),(5,3),(6,1),(7,5),(8,6),(9,7)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;假設有這些 label 及分數，透過 map 的方式將 Seq[string] 轉成 Map[Int,Double]&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val labels = Seq(
  &quot;1:0.5,4:0.3,8:0.4&quot; ,
  &quot;2:0.7,7:0.9&quot;
)
val personMaps = labels.map(_.split(&quot;,&quot;).map(
  linfo =&amp;gt; {
    (linfo.split(&quot;:&quot;)(0).toInt , linfo.split(&quot;:&quot;)(1).toDouble)
  }
).toMap)
personMaps.foreach(println(_))

// person1 : Map(1 -&amp;gt; 0.5, 4 -&amp;gt; 0.3, 8 -&amp;gt; 0.4)
// person2 : Map(2 -&amp;gt; 0.7, 7 -&amp;gt; 0.9)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;接著只要照剛剛的 findLabelSequence 順序找看看該 Key 是否存在，第一個找到的話就變成該 label 的一個 signatureIndex．&lt;br /&gt;
person1 根據 findLabelSequence 算的 signatureIndex 會是 8．&lt;br /&gt;
person2 根據 findLabelSequence 算的 signatureIndex 會是 2．&lt;br /&gt;
接著可以建立 signature matrix [8] 和 [2]，接著只要有新的 person(person3) 進來，如果透過 findLabelSequence 算出來的值是 8，就可以把該 person 放到 [8] 這著 bucket 裡．&lt;br /&gt;
代表 person1 和 person3 是屬於同一類型的人．&lt;br /&gt;
接著繼續實作…&lt;br /&gt;
給一組 Map (Map(1 -&amp;gt; 0.5, 4 -&amp;gt; 0.3, 8 -&amp;gt; 0.4)) 和 findLabelSequence (Seq((1,8),(2,2),(3,4),(4,9),(5,3),(6,1),(7,5),(8,6),(9,7))) 來找到 signatureIndex&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def findSignatureIndex(labels:Map[Int,Double],findLabelSequence:Seq[Tuple2[Int,Int]]):Int = {
    println(&quot;labels -&amp;gt; &quot; + labels)
    println(&quot;findLabelSequence -&amp;gt; &quot; + findLabelSequence)
	val resultList = findLabelSequence.filter(s =&amp;gt; labels.contains(s._2)).take(1)
	if(resultList.isEmpty) {
	  0
	} else {
	  resultList(0)._2
	}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;找出每個人的 signatureIndex&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val labels = Seq(
  &quot;1:0.5,4:0.3,8:0.4&quot; ,
  &quot;2:0.7,7:0.9&quot;
)

val personMaps = labels.map(_.split(&quot;,&quot;).map(
  linfo =&amp;gt; {
    (linfo.split(&quot;:&quot;)(0).toInt , linfo.split(&quot;:&quot;)(1).toDouble)
  }
).toMap)
val findLabelSequence = shuffleIndex(Stream.range(1,10).toArray).zipWithIndex.sortWith(_._1 &amp;lt; _._1).map(i =&amp;gt; (i._1 , (i._2 + 1)))
val signatureIndex = personMaps.map(m =&amp;gt; findSignatureIndex(m , findLabelSequence))
signatureIndex.foreach(println(_))

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;執行結果&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;labels -&amp;gt; Map(1 -&amp;gt; 0.5, 4 -&amp;gt; 0.3, 8 -&amp;gt; 0.4)
findLabelSequence -&amp;gt; WrappedArray((1,2), (2,9), (3,8), (4,1), (5,5), (6,6), (7,3), (8,4), (9,7))
labels -&amp;gt; Map(2 -&amp;gt; 0.7, 7 -&amp;gt; 0.9)
findLabelSequence -&amp;gt; WrappedArray((1,2), (2,9), (3,8), (4,1), (5,5), (6,6), (7,3), (8,4), (9,7))
8
2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Thu, 21 Feb 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/spark/2019/02/21/spark-LSH.html</link>
        <guid isPermaLink="true">http://localhost:4000/spark/2019/02/21/spark-LSH.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
      <item>
        <title>Spark Matrix</title>
        <description>&lt;h3 id=&quot;spark-matrix-計算-cosine-similarity&quot;&gt;spark matrix 計算 cosine Similarity&lt;/h3&gt;

&lt;p&gt;假設有一群人的資料，有每個人的 label 跟分數．將每個人的 label 與分數轉成向量後計算彼此的 cosine Similarity，透過 cosine Similarity 來看這些人的相似程度如何．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val personDatas = Seq(
  (&quot;person1&quot;,&quot;1:0.5,2:0.3,3:0.4&quot;) ,
  (&quot;person2&quot;,&quot;2:0.7&quot;) ,
  (&quot;person3&quot;,&quot;1:0.9,3:0.1&quot;) ,
  (&quot;person4&quot;,&quot;1:0.3,2:0.6,3:0.8&quot;)
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;person1 的 label 分數轉成 [0.5,0.3,0.4] 代表一個維度為 3 的向量．&lt;br /&gt;
person2 的 label 分數轉成 [0.0,0.7,0.0]．&lt;br /&gt;
然後用 cosine Similarity 的公式來計算 [0.5,0.3,0.4] 與 [0.0,0.7,0.0] 的 cosine Similarity value．&lt;/p&gt;

&lt;p&gt;接著將上面的資料轉成 IndexedRowMatrix．透過 RDD 的 zipWithIndex，可以取得每個元素的 index 從 0 開始 :&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val comparePersons = spark.sparkContext.parallelize(personDatas).toDF(&quot;id&quot;,&quot;labels&quot;).cache()

val allPerson = comparePersons.rdd.zipWithIndex.map {
  case (row , index) =&amp;gt; {
    val id = row.getAs[String](&quot;id&quot;)
    val labels = row.getAs[String](&quot;labels&quot;).split(&quot;,&quot;)
    val lindexs = labels.map(lstr =&amp;gt; (lstr.split(&quot;:&quot;)(0).toInt - 1))
    val lvalues = labels.map(lstr =&amp;gt; lstr.split(&quot;:&quot;)(1).toDouble)
    val labelVector =  org.apache.spark.mllib.linalg.Vectors.sparse(4, lindexs, lvalues)
    (id , new IndexedRow(index , labelVector) )
  }
}.cache()

val indexRowMatrix = new IndexedRowMatrix(allPerson.map(_._2))

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;將 IndexedRowMatrix 轉成 CoordinateMatrix 後轉置(transpose)，然後再轉成 IndexedRowMatrix，
利用 IndexedRowMatrix 的 columnSimilarities 來幫忙算出每個向量之間的相似度 (cosine similarity)．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val newMatrix = indexRowMatrix.toCoordinateMatrix.transpose.toIndexedRowMatrix()
val newCosValues = newMatrix.columnSimilarities()
newMatrix.rows.foreach(println(_))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;印出的結果會是&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MatrixEntry(0,1,0.42426406871192845)
MatrixEntry(0,2,0.7652514332541697)
MatrixEntry(0,3,0.8804710999221752)
MatrixEntry(1,3,0.5746957711326908)
MatrixEntry(2,3,0.37020976437050546)

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;columnsimilarities-使用說明&quot;&gt;columnSimilarities 使用說明&lt;/h3&gt;
&lt;p&gt;1.原來的矩陣&lt;br /&gt;
[0.5 , 0.3 , 0.4 , 0]&lt;br /&gt;
[0 , 0.7 , 0 , 0]&lt;br /&gt;
[0.9 , 0 , 0.1 , 0]&lt;br /&gt;
如果沒轉置使用 columnSimilarities 的話，結果會是&lt;br /&gt;
[0.5 , 0 , 0.9] 跟 [0.3 , 0.7 , 0] 的相似度 0.19130412280981776&lt;br /&gt;
[0.5 , 0 , 0.9] 跟 [0.4 , 0 , 0.1] 的相似度 0.6831571287757409&lt;br /&gt;
[0.5 , 0 , 0.9] 跟 [0 , 0 , 0] 的相似度 NaN (無法計算不顯示)&lt;br /&gt;
[0.3 , 0.7 , 0] 跟 [0.4 , 0 , 0.1] 的相似度 0.3821578531790892&lt;br /&gt;
[0.3 , 0.7 , 0] 跟 [0 , 0 , 0] 的相似度 NaN (無法計算不顯示)&lt;br /&gt;
[0.4 , 0 , 0.1] 跟 [0 , 0 , 0] 的相似度 NaN (無法計算不顯示)
這樣並不是正確的結果，因為希望的是上面三個向量彼此的相似度．所以要將矩陣轉置．&lt;/p&gt;

&lt;p&gt;2.轉置後的矩陣&lt;br /&gt;
IndexedRow(0,[0.5,0.0,0.9])&lt;br /&gt;
IndexedRow(1,[0.3,0.7,0.0])&lt;br /&gt;
IndexedRow(2,[0.4,0.0,0.1])&lt;br /&gt;
IndexedRow(3,[0.0,0.0,0.0])&lt;br /&gt;
使用 columnSimilarities 的話，結果會是&lt;br /&gt;
[0.5 , 0.3 , 0.4 , 0] 跟 [0 , 0.7 , 0 , 0] 的相似度 0.42426406871192845&lt;br /&gt;
[0.5 , 0.3 , 0.4 , 0] 跟 [0.9 , 0 , 0.1 , 0] 的相似度 0.7652514332541697&lt;br /&gt;
[0 , 0.7 , 0 , 0] 跟  [0.9 , 0 , 0.1 , 0] 的相似度 0 (相似度 0 的話就不顯示)&lt;br /&gt;
可以用下列的 cosineSimilarityVerifyTest 來驗證相似度是否正確．計算兩個向量的 cosine Similarity，越大代表越像．&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;test(&quot;cosineSimilarityVerifyTest&quot;) {
	//[0.5 , 0 , 0.9] 跟 [0 , 0 , 0] 的相似度 0
	val query = List[Double](0.5 , 0.3 , 0.4 , 0)
	val labels = List[Double](0 , 0.7 , 0 , 0)
	val cv1 = cosineSimilarity(query.toArray , labels.toArray)
	println(&quot;cv1 : &quot; + cv1) // cv1 : 0.42426406871192845
}

def cosineSimilarity(x: Array[Double], y: Array[Double]): Double = {
require(x.size == y.size)
genDot(x, y)/(magnitude(x) * magnitude(y))
}

def genDot(x: Array[Double], y: Array[Double]): Double = {
(for((a, b) &amp;lt;- x.zip(y)) yield a * b).sum
}

def magnitude(x: Array[Double]): Double = {
math.sqrt(x.map(i =&amp;gt; i*i).sum)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;其他參考作法&quot;&gt;其他參考作法&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val spark = SparkSession.builder()
  .master(&quot;local[*]&quot;)
  .appName(&quot;testtest&quot;)
  .getOrCreate()

import spark.implicits._

val testSeq = Seq(
  (&quot;1&quot;,&quot;1:0.5,2:0.3,3:0.4&quot;) ,
  (&quot;2&quot;,&quot;2:0.7&quot;) ,
  (&quot;3&quot;,&quot;1:0.9,3:0.1&quot;)
)
val rddEntrys = testSeq.map {
  case(i , labels) =&amp;gt; {
    val entrys = labels.split(&quot;,&quot;).map(l =&amp;gt; {
      val index = l.split(&quot;:&quot;)(0).toInt - 1
      val v = l.split(&quot;:&quot;)(1).toDouble
      new MatrixEntry(index , (i.toLong - 1) , v )
    })
    entrys
  }
}.flatten

val temp = spark.sparkContext.parallelize(rddEntrys)

val corMatrix = new CoordinateMatrix(temp)
corMatrix.entries.foreach(println(_))

val cv = corMatrix.toIndexedRowMatrix().columnSimilarities()
cv.entries.foreach(println(_))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;印出結果&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MatrixEntry(0,1,0.42426406871192845)
MatrixEntry(0,2,0.7652514332541697)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;val spark = SparkSession.builder()
  .master(&quot;local[*]&quot;)
  .appName(&quot;testtest&quot;)
  .getOrCreate()

import spark.implicits._

val testSeq = Seq(
  (&quot;1&quot;,&quot;1:0.5,2:0.3,3:0.4&quot;) ,
  (&quot;2&quot;,&quot;2:0.7&quot;) ,
  (&quot;3&quot;,&quot;1:0.9,3:0.1&quot;)
)
val rddEntrys = testSeq.map {
  case(i , labels) =&amp;gt; {
    val entrys = labels.split(&quot;,&quot;).map(l =&amp;gt; {
      val index = l.split(&quot;:&quot;)(0).toInt - 1
      val v = l.split(&quot;:&quot;)(1).toDouble
      (index , ((i.toLong - 1).toInt , v) )
    })
    entrys
  }
}.flatten

val indexedRows = spark.sparkContext.parallelize(rddEntrys).groupByKey.map {
  case(i, vectorEntries) =&amp;gt; {
    IndexedRow(i, Vectors.sparse(3, vectorEntries.toSeq))
  }
}
val numRows = indexedRows.count

val cv = new IndexedRowMatrix(indexedRows, numRows, 3).columnSimilarities()
cv.entries.foreach(println(_))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;印出結果&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;MatrixEntry(0,1,0.42426406871192845)
MatrixEntry(0,2,0.7652514332541697)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Wed, 20 Feb 2019 00:00:00 +0800</pubDate>
        <link>http://localhost:4000/spark/2019/02/20/spark-matrix.html</link>
        <guid isPermaLink="true">http://localhost:4000/spark/2019/02/20/spark-matrix.html</guid>
        
        
        <category>spark</category>
        
      </item>
    
  </channel>
</rss>
